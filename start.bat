@echo off
REM AI Companion Chat í”„ë¡œì íŠ¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
REM Windowsìš©

echo ğŸš€ AI Companion Chat í”„ë¡œì íŠ¸ ì‹œì‘ ì¤‘...
echo.

cd /d "%~dp0"

REM Python ê°€ìƒí™˜ê²½ í™•ì¸
if not exist ".venv" (
    echo âš ï¸  ê°€ìƒí™˜ê²½ì´ ì—†ìŠµë‹ˆë‹¤. ìƒì„± ì¤‘...
    python -m venv .venv
    echo âœ… ê°€ìƒí™˜ê²½ ìƒì„± ì™„ë£Œ
)

REM ê°€ìƒí™˜ê²½ í™œì„±í™”
echo ğŸ“¦ ê°€ìƒí™˜ê²½ í™œì„±í™” ì¤‘...
call .venv\Scripts\activate.bat

REM Python ì˜ì¡´ì„± í™•ì¸
python -c "import fastapi" 2>nul
if errorlevel 1 (
    echo âš ï¸  Python ì˜ì¡´ì„±ì´ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘...
    pip install -r requirements.txt
    echo âœ… ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ
)

REM Frontend ì˜ì¡´ì„± í™•ì¸
if not exist "frontend\node_modules" (
    echo âš ï¸  Frontend ì˜ì¡´ì„±ì´ ì—†ìŠµë‹ˆë‹¤. ì„¤ì¹˜ ì¤‘...
    cd frontend
    call npm install
    cd ..
    echo âœ… Frontend ì˜ì¡´ì„± ì„¤ì¹˜ ì™„ë£Œ
)

REM Ollama ì„œë²„ í™•ì¸
echo ğŸ” Ollama ì„œë²„ í™•ì¸ ì¤‘...
curl -s http://127.0.0.1:11434/api/tags >nul 2>&1
if errorlevel 1 (
    echo âš ï¸  Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤.
    echo ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ Ollamaë¥¼ ì‹œì‘í•˜ì„¸ìš”:
    echo ollama serve
    echo.
    pause
)

REM Backend ì‹¤í–‰ (ìƒˆ ì°½)
echo ğŸ”§ Backend ì„œë²„ ì‹œì‘ ì¤‘...
start "AI Companion Backend" cmd /k "call .venv\Scripts\activate.bat && uvicorn backend.main:app --reload --port 8000"

REM ì ì‹œ ëŒ€ê¸°
timeout /t 2 /nobreak >nul

REM Frontend ì‹¤í–‰ (ìƒˆ ì°½)
echo ğŸ¨ Frontend ì„œë²„ ì‹œì‘ ì¤‘...
cd frontend
start "AI Companion Frontend" cmd /k "npm run dev"
cd ..

echo.
echo â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo âœ… í”„ë¡œì íŠ¸ê°€ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!
echo â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
echo.
echo Backend:  http://127.0.0.1:8000
echo Frontend: http://localhost:3000
echo.
echo ê° ì°½ì„ ë‹«ìœ¼ë©´ ì„œë²„ê°€ ì¢…ë£Œë©ë‹ˆë‹¤.
echo.
pause

